---
title           : "Personality-Situation Transactions as Coupled Oscillators"
shorttitle      : "My preregistration"
date            : "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"
author: 
  - name        : Emorie Beck
    affiliation : 1
  - name        : Niclas Kuiper
    affiliation : "1,2"
affiliation:
  - id          : 1
    institution : Northwestern University Feinberg School of Medicine
  - id          : 2
    institution : Konstanz Business School
output: prereg::cos_prereg
editor_options: 
  chunk_output_type: console
---

```{r}
library(knitr)
library(brms)
library(lubridate)
library(plyr)
library(tidyverse)
```

# Study Information

## Title

```{=html}
<!-- Provide the working title of your study. It may be the same title that you submit for publication of your final manuscript, but it is not a requirement. The title should be a specific and informative description of a project. Vague titles such as 'Fruit fly preregistration plan' are not appropriate.

Example: Effect of sugar on brownie tastiness. -->
```
`r rmarkdown::metadata$title`

## Description
<!-- Please give a brief description of your study, including some background, the purpose of the of the study, or broad research questions. The description should be no longer than the length of an abstract. It can give some context for the proposed study, but great detail is not needed here for your preregistration.

Example: Though there is strong evidence to suggest that sugar affects taste preferences, the effect has never been demonstrated in brownies. Therefore, we will measure taste preference for four different levels of sugar concentration in a standard brownie recipe to determine if the effect exists in this pastry. -->
There has long been recognition that person and situation characteristics interact in producing behavior. However, estimating such person-situation interactions or transactions has remained largely elusive. There are several reasons why this is the case. First, work on person-situation transactions often focuses on so-called fixed effects, or person-situation transactions on average across people, even when looking at within-person patterns. Such approaches fail to recognize that average effects of 0 may indicate a non-triviual number of individuals who have positive or negative effects. Second, most work on person-situation transactions assumes linear relationships between persons and situations. However, if person and situation variables are considered as systems, it makes little sense to consider their relationships as linear. Rather, they should be captured as non-linear interacting processes within a system. 

The proposed project aims to investigate non-linear dynamics between changes in personality states and situational states using multilevel coupled oscillator models [@Butner2014; @Butner2005; @Butler2019].  

## Research Questions  
1. Are changes in personality states and situation perceptions associated with level of each?  
2. Are changes individual differences in in teh degree to which personality states and situation perceptions associated with level of each?  
3. How consistent are these across studies?  

## Hypotheses

1. Predicted average associations will be based on previous research examining personality state-situation characteristic contingencies (e.g., Kuper et al., 2021ab; Rauthmann et al., 2016; Sherman et al., 2015). Specifically, we expect that changes in each of the follwing will be associated with level of the other: 

```{r, echo = F, message = 'hide', warning = F}
tribble(
  ~Situation  , ~E, ~A, ~C, ~N, ~O,
  "Duty"      , "", "","+", "", "",
  "Intellect" , "", "", "", "","+",
  "Adversity" , "","-", "","+", "",
  "Mating"    ,"+", "", "", "", "",
  "pOsitivity","+", "", "","-", "",
  "Negativity","-", "", "","+", "",
  "Deception" , "","-", "","+", "",
  "Sociality" ,"+","+", "", "", ""
) %>% kable(.)
```

# Data Description  
## Datasets used  

<!-- Name and briefly describe the dataset(s), and if applicable, the subsets of the data you plan to use.Useful information to include here is the type of data (e.g., cross-sectional or longitudinal), the general content of the questions, and some details about the respondents. In the case of longitudinal data, information about the survey’s waves is useful as well. Mention the most relevant information so that readers do not have to search for the information themselves. -->

### Personality and Interpersonal Roles Study (PAIRS)  
The PAIRS study was a seven wave longitudinal study collected at Washington University in St. Louis. Approximately 350 individuals completed at least one wave of survey data, experience sampling method data, and electronically activated recorder data. In the proposed study, we will be using the third wave of ESM data, which corresponds to the seventh wave of survey data. Although all waves collected a variety of data on personality, emotions, situations, and more, the third wave additionally included a measure of situation characteristics, the DIAMONDS. In the proposed study, we will make sure of 9 indicators of Big Five personality (representing each of the Big Five except Openness) and 8 indicators of situations.  

### Intentional Personality Change Study (IPCS)  
The IPCS study is an ongoing longitudinal study collected at Washington University in St. Louis. Approximately 200 individuals completed the first wave of survey and ESM responses. In the proposed study, we will use the first wave of ESM data, which includes both measures of personality states as well as the DIAMONDS indicators. Specifically, we will use 15 indicators of Big Five personality (3 for each of the Big Five) and 8 indicators of situations.  


## Data availability  
<!-- Specify the degree to which the datasets are open or publicly available. -->
Dataset   |   Availability  
-------   |   -----------
PAIRS   |   The dataset is publicly available  
IPCS    |   The dataset is publicly available  
<!-- The dataset is publicly available   -->
<!-- The dataset is available through protected access   -->
<!-- The dataset is not publicly available   -->

## Data access (optional)
<!-- If there are any restrictions to accessing the dataset, please describe this here. -->
Although most of the data are publically available, the data maintainers request contacting them in order to avoid data overuse or overlap in their use.  

Dataset   |   Availability  
-------   |   -----------
PAIRS   |   Please contact Simine Vazire, simine@gmail.com  
IPCS    |   Please contact Emorie Beck, emorie_beck@alumni.brown.edu  

## Data identifiers (optional)  
<!-- Please provide a URL, DOI, or other persistent, unique identifier of the dataset. -->

## Access date  
<!-- Specify the download or data access date. If the data were accessed multiple times by different team members, specify the download date for that data that will be used in the statistical analysis. -->

## Data collection procedures  
<!-- If the data collection procedure is well documented, provide a link to that information. If the data collection procedure is not well documented, describe, to the best of your ability, how data were collected. Describe the representativeness of the sample and any possible biases stemming from the data collection. -->

### PAIRS  
(Adapted from Beck \& Jackson, 2020a)

Undergraduate students at Washington University completed experience sampling method (ESM) surveys as part of the longitudinal Personality and Intimate Relationships Study (PAIRS; Vazire, Wilson, Solomon, Bollich, Harris, Weston, Mike, & Jackson, 2015). For Wave 3, X (X males, X females) students with a mean age of X (SD = X) completed ESM surveys. For each wave, participants were paid \$20 for the laboratory portion of each assessment and entered into a lottery with the chance to win \$100 for completing ESM surveys (if all ESM surveys were completed, the odds of winning were 1 in 10). Participants’ self-reported ethnicities indicated that 56\% identified as Caucasian, 23\% as Asian, 9\% as Black, and 12\% as other. 2\% of participants did not report their ethnicities. 

Before completing the ESM component, participants first completed a two-hour laboratory experiment in which they completed multiple questionnaires as well as several other tasks, which will not be considered in the current study. After completing the laboratory portion, the researchers provided participants with instructions on the ESM component of the study. Participants received four emails per day with links to the ESM survey for two weeks. Including a practice survey, there were thus 59 possible surveys for each participant. 

Participants responded to questions about their situation, emotions, and behavior in the last hour. Nine personality items were taken from the BFI-44 (John, Naumann, & Soto, 2008), but were modified to reflect the collection periods of the ESM survey (e.g. “From 5-6 pm, how engaged were you?”). As noted in Wilson, Thompson, and Vazire (2016), “The shortened BFI scale was comprised of two items per construct taken from the original BFI-44, making sure that each item (a) made sense at the state level; (b) assessed a different facet of the respective Big Five construct; (c) avoided difficult vocabulary words, and (d) had a comparatively high item-total correlation” (p. 4). Participants responded on a 5-point scale from 1 “Not a lot” to 5 “Very.” With the exception of Agreeableness items (2), which were only collected if the participant indicated they were interacting with someone in the previous hour, participants responded to all items at each measurement point. In addition, items from the Openness to Experience domain were not included. In this third wave, an ultra brief measure of the DIAMONDS, the S8-I, was included. A few additional state manifestations of personality were also included, measuring participants' state self-esteem, positve emotion, and negative emotion, each of which were measured in the same way as the BFI items.  

### IPCS  
Participants in this study were drawn from a larger study personality intervention study.

Participants responded to two types of surveys: trait and state (Experience Sampling Method; ESM) measures, for which they were paid separately. For the first wave, which is the only wave used in the present study, participants were recruited from the psychology subject pool at Washington University in St. Louis. Participants were told that the study posted on the recruitment website was the first wave of a longer longitudinal study they would be offered the opportunity to take part in.

Participants were brought into the lab between October 2018 and December 2019, where a research assistant or the first author explained the study procedure to them and walked them through the consent procedure. If they consented, participants were led to a room where they could fill out a form to opt into the ESM portion of the study. They then completed baseline trait measures using the Qualtrics Survey Platform. After, the participants were debriefed, paid \$10 in cash and, if they opted into the ESM portion of the study, the ESM survey procedure was explained to them. 

Participants then received ESM measures 4 times a day for a two weeks (max n = 56). The survey platform was built by the first author using the jsPsych library. Additional javascript controllers were written for the purpose of this study and are available on the first author's GitHub. Start times were based on times participants indicated they would like to receive their first survey. Surveys were sent every 4 hours, meaning that the surveys spanned a 12 hour period from the first time participants indicated. Participants received their first survey at their chosen time on the Monday following their in-lab session. They were compensated \$0.50 for each survey completed for a maximum of $28. To incentivize responding, participants who completed at least 50 surveys received a "bonus" for a total compensation of \$30, which was distributed as an Amazon Gift Card.

Additional waves of data were completed remotely online but will not be used in the present study. See Beck \& Jackson (2021) for an overview of additional data.  

## Codebook  
<!-- Some studies offer codebooks to describe their data. If such a codebook is publicly available, link, cite, or upload the document. If not, provide other available documentation. Also provide guidance on what parts of the codebook or other documentation are most relevant. -->

# Variables

<!-- In this section you can describe all variables (both manipulated and measured variables) that will later be used in your confirmatory analysis plan. In your analysis plan, you will have the opportunity to describe how each variable will be used. If you have variables which you are measuring for exploratory analyses, you are not required to list them, though you are permitted to do so. -->

## Measured variables  

```{=html}
<!-- Describe each variable that you will measure. This will include outcome measures, as well as any predictors or covariates that you will measure. You do not need to include any variables that you plan on collecting if they are not going to be included in the confirmatory analyses of this study.

Observational studies and meta-analyses will include only measured variables. As with the previous questions, the answers here must be precise. For example, 'intelligence,' 'accuracy,' 'aggression,' and 'color' are too vague. Acceptable alternatives could be 'IQ as measured by Wechsler Adult Intelligence Scale' 'percent correct,' 'number of threat displays,' and 'percent reflectance at 400 nm.'

Example: The single outcome variable will be the perceived tastiness of the single brownie each participant will eat. We will measure this by asking participants ‘How much did you enjoy eating the brownie’ (on a scale of 1-7, 1 being 'not at all', 7 being 'a great deal') and 'How good did the brownie taste' (on a scale of 1-7, 1 being 'very bad', 7 being 'very good'). -->
```

The proposed study will focus on two main categories of measures: personality states and situation characteristics. These measures differ slightly across studies, as documented below. 

## Unit of analysis (optional)
<!-- Which units of analysis (respondents, cases, etc.) will be included or excluded in your study? Taking these inclusion and exclusion criteria into account, indicate the expected sample size of the data you’ll be using for your statistical analyses. If you have a research question about a certain group you may need to exclude participants based on one or more characteristics. Be very specific when describing these characteristics so that readers will be able to redo your moves easily. -->

Enter your response here.

## Missing data (optional)  
<!-- What do you know about missing data in the dataset (i.e., overall missingness rate, information about differential dropout)? How will you deal with incomplete or missing data? Provide descriptive information, if available, on the amount of missing data for each variable you will usein the statistical analyses. Based on this information, provide a new expected sample size. -->

Enter your response here.

## Statistical outliers (optional)  
<!-- How will you define what a statistical outlier is in your data and what will you do when you encounter them? If you plan to remove outliers, provide a new expected sample size. If you expect to remove many outliers or if you are unsure about your outlier handling strategy, it is good practice to preregister analyses including and excluding outliers. Note that this will be the definitive expected sample size for your study and you will use this number to do any power analyses. -->

Enter your response here.

## Sampling weights (optional)  
<!-- Are there sampling weights available with this dataset? If so, are you using them or are you using your own sampling weights? Sampling weights can be useful in secondary data analysis because the sample may not be entirely representative of the population you are interested in. -->

Enter your response here.

# Knowledge of Data  
## Prior Publication/Dissemination  
<!-- List the publications, working papers, and conference presentations you have worked on that are based on the dataset you will use. For each work, list the variables you analyzed, but limit yourself to variables that are relevant to the proposed analysis. If the dataset is longitudinal, also state which wave of the dataset you analyzed. Specify the previous works for each co-author separately. -->

Enter your response here.

## Prior knowledge  
<!-- Disclose any prior knowledge you may have about the dataset that is relevant for the proposed analysis. If you do not have any prior knowledge of it, please state so. Your prior knowledge could stem from working with the data first-hand, from reading previously published research, or from codebooks. Provide prior knowledge for every author separately. -->

Enter your response here.

# Analysis Plan

<!-- You may describe one or more confirmatory analysis in this preregistration. Please remember that all analyses specified below must be reported in the final article, and any additional analyses must be noted as exploratory or hypothesis generating.

A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis. You are allowed to describe any exploratory work here, but a clear confirmatory analysis is required. -->

## Statistical models  

<!-- What statistical model will you use to test each hypothesis? Please include the type of model (e.g. ANOVA, multiple regression, SEM, etc) and the specification of the model (this includes each variable that will be included as predictors, outcomes, or covariates). Please specify any interactions, subgroup analyses, pairwise or complex contrasts, or follow-up tests from omnibus tests. If you plan on using any positive controls, negative controls, or manipulation checks you may mention that here. Remember that any test not included here must be noted as an exploratory test in your final article.

This is perhaps the most important and most complicated question within the preregistration. As with all of the other questions, the key is to provide a specific recipe for analyzing the collected data. Ask yourself: is enough detail provided to run the same analysis again with the information provided by the user? Be aware for instances where the statistical models appear specific, but actually leave openings for the precise test. See the following examples:

- If someone specifies a 2x3 ANOVA with both factors within subjects, there is still flexibility with the various types of ANOVAs that could be run. Either a repeated measures ANOVA (RMANOVA) or a multivariate ANOVA (MANOVA) could be used for that design, which are two different tests. 
- If you are going to perform a sequential analysis and check after 50, 100, and 150 samples, you must also specify the p-values you’ll test against at those three points.

Example:  We will use a one-way between subjects ANOVA to analyze our results. The manipulated, categorical independent variable is 'sugar' whereas the dependent variable is our taste index. -->

To estimate coupled non-linear oscillations between personality states and situation characteristics, we will use a series of multivariate multilevel change as outcome models. In these models, we will predict changes in personality states and situation characteristics from their level and their difference in level (i.e. their interaction). The form of the model is as follows: 

Level 1: 
$\Delta~Personality_{it} = \beta_{0t,p} + \beta_{1t,p}*Personality_{it} + \beta_{2t,p}*Situation_{it} + \beta_{3tp}*Personality_{it,p}*Situation_{it,p} + \epsilon_{it,p}$
$\Delta~Situation_{it} = \beta_{0t,s} + \beta_{1t,s}*Personality_{it} + \beta_{2t,s}*Situation_{it} + \beta_{3t,s}*Personality_{it}*Situation_{it} + \epsilon_{it,s}$

Level 2: 
$\beta_{0t,p} = \gamma_{00,p} + u_{0t,p}$
$\beta_{1t,p} = \gamma_{10,p} + u_{1t,p}$
$\beta_{2t,p} = \gamma_{20,p} + u_{2t,p}$
$\beta_{3t,p} = \gamma_{30,p} + u_{3t,p}$

$\beta_{0t,s} = \gamma_{00,s} + u_{0t,s}$
$\beta_{1t,s} = \gamma_{10,s} + u_{1t,s}$
$\beta_{2t,s} = \gamma_{20,s} + u_{2t,s}$
$\beta_{3t,s} = \gamma_{30,s} + u_{3t,s}$, 

where $\Delta~Personality_{it}$ is the first derivative (i.e. velocity) of the personality state indicator, $\Delta~Situation_{it}$ is the first derivative of the situation characteristic indicator, $Personality_{it}$ is the level of the personality state at time $t$, $Situation_{it}$ is the level of the situation characeristic at time $t$.  

$\gamma_{10,p}$ is the strength of the equilibria point for the personality state, adjusting for situation characteristics and the difference (interaction) between the personality state and situation characteristics. $\gamma_{10,s}$ is the strength of the equilibria point for the situation characteristic, adjusting for personality state and the difference (interaction) between the personality state and situation characteristics. 

In these models, including an interaction can move equilbria points or govern their presence. Thus, $\gamma_{30,p}$ and $\gamma_{30,s}$ capture the displacement of the equlibria points. 

To find the equilibria points, we simply solve the equations when $\Delta~Personality_{it}$ and $\Delta~Situation_{it}$ are equal to zero. In other words for personality, we solve: 
$0 = \gamma_{00,p} + \gamma_{10,p}*Personality_{it} + \gamma_{20,p}*Situation_{it} + \gamma_{30,p}*Personality_{it,p}*Situation_{it,p}$, subbing in the estimated coefficients. 

To test this model, we will use the emotion features from the IPCS study, which are not being used in the present study, to remain blinded.  

```{r}
load("~/Box/network/other projects/ps-oscillators/03-data/02-ipcs/01-raw-data/esm_cleaned_combined_2021-04-07.RData")
emo <- emo %>% mutate(Date = as.character(Date)
                       , Date = ifelse(SID == 212, str_replace_all(Date, "2019-01", "2020-01"), Date)
                       , Date = as.Date(Date)) %>%
  group_by(SID) %>%
  mutate(StartDate = min(Date)) %>%
  ungroup()
missing_fun <- function(d){
  first_day <- min(d$Date) # get first day
  hourBlock <- unique(d$`Hour Block 1`) # get first hour block
  max_day <- max(d$Day); max_day <- ifelse(max_day < 14, 14, max_day) # get number of days
  d2 <- d %>% #mutate(StartDate = ifelse(is.na(StartDate), min(Date, na.), StartDate))
    full_join(crossing(
      Day = seq(0,max_day,1),
      HourBlock = 1:4,
      StartDate = first_day,
      `Hour Block 1` = hourBlock)) %>% # cross existing data with "perfect" data
    arrange(Day, HourBlock) %>%
    mutate(Date = StartDate + Day,
           Hour = ifelse(is.na(Hour), `Hour Block 1` + (HourBlock-1)*4, Hour),
           Minute = ifelse(is.na(Minute), "00", Minute))
  d2$Date[d2$Hour > 23] <- d2$Date[d2$Hour > 23] + 1 # some day blocks span days
  d2$Hour[d2$Hour > 23] <- d2$Hour[d2$Hour > 23] - 24 # some day blocks span days
  d2 <- d2 %>% mutate(
    Full_Date = sprintf("%s %s:%s", as.character(Date), Hour, Minute)) %>%
    select(-`Hour Block 1`, -StartDate) 
}

# create a data frame of timing info 
ipcs_times <- emo %>% 
  select(SID, StartDate, Date, Hour, Minute, Day, `Hour Block 1`, HourBlock) %>%
  distinct() %>%
  mutate(Minute = str_remove_all(Minute, ".csv"),
         Minute = ifelse(as.numeric(Minute) < 10, sprintf("0%s", Minute), Minute)) %>%
  arrange(SID, Date) %>%
  group_by(SID) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, missing_fun)) %>%
  unnest(data) %>%
  arrange(SID, Date, Hour) %>%
  group_by(SID) %>%
  mutate(all_beeps = seq(1, n(), 1)) %>%
  ungroup()

emo <- emo %>% 
  select(SID, trait, responses2, Date, Hour, Minute, Day, HourBlock) %>%
  mutate(Minute = str_remove_all(Minute, ".csv")
         , responses2 = as.numeric(responses2)) %>%
  filter(trait %in% c("happy", "purposeful")) %>%
  full_join(ipcs_times) %>%
  distinct() %>%
  arrange(SID, all_beeps, trait)

```

### MLM
```{r}
emo_ct <- emo %>%
  filter(!is.na(trait)) %>%
  pivot_wider(names_from = "trait", values_from = "responses2") %>%
  mutate(Full_Date = ifelse(is.na(Full_Date), sprintf("%s %s:%s", as.character(Date), Hour, Minute), Full_Date)) %>%
  group_by(SID) %>%
  arrange(SID, Date, Hour, Minute) %>%
  mutate(tdif = as.numeric(difftime(ymd_hm(Full_Date), lag(ymd_hm(Full_Date)), units = "hours"))) %>%
  filter(is.na(tdif) | tdif > 1) %>%
  mutate_at(vars(happy, purposeful), lst(c = ~as.numeric(scale(., center = T, scale = F)))) %>%
  mutate_at(vars(happy_c, purposeful_c), lst(delta = ~((.) - lag(.))/tdif))

fp <- paste(c("happy_delta", "happy_c*purposeful_c + (happy_c*purposeful_c | SID)"), collapse = " ~ ")
fs <- paste(c("purposeful_delta", "happy_c*purposeful_c + (happy*purposeful_c | SID)"), collapse = " ~ ")
f2 <- mvbrmsformula(bf(fp), bf(fs))

m <- brm(f2, data = emo_ct, iter = 1000, warmup = 500, cores = 4)

fixef(m) # nothing is significant

rf <- coef(m, probs = c(0.025, 0.975))[[1]] %>% array_tree(3) %>% 
      tibble(term = names(.), data = .) %>% 
      mutate(data = map(data, ~(.) %>% data.frame %>% 
        rownames_to_column("SID"))) %>% 
      unnest(data) %>% 
      select(term, SID, estimate = Estimate, conf.low = Q2.5, conf.high = Q97.5)
```

### Idiographic  
```{r}
round_p1_down <- function(x){
  x <- round(x, 2)
  sp_x <- str_split(x, pattern = "[.]")[[1]]
  if(sign(x) == -1) sp_x[2] <- round_any(as.numeric(sp_x[2]), 10, ceiling)
  sp_x[2] <- str_sub(sp_x[2], 1, 1)
  y <- as.numeric(paste(sp_x[1], sp_x[2], sep = "."))
}

fp <- paste(c("happy_c_delta", "happy_c*purposeful_c"), collapse = " ~ ")
fs <- paste(c("purposeful_c_delta", "happy_c*purposeful_c"), collapse = " ~ ")
f2 <- mvbrmsformula(bf(fp), bf(fs))

nested_emo_ct <- emo_ct %>% 
  group_by(SID) %>%
  nest() %>%
  filter(map_dbl(data, nrow) > 25) %>%
  ungroup()

m <- brm(f2, data = nested_emo_ct$data[[1]], iter = 1000, warmup = 500, cores = 4)
min_h <- round_p1_down(min(m$data$happy_c)); min_p <- round_p1_down(min(m$data$purposeful_c))
max_h <- round_p1_down(max(m$data$happy_c)); max_p <- round_p1_down(max(m$data$purposeful_c))
p <- predict(m, newdata = crossing(happy_c = seq(min_h,max_h,.2), purposeful_c = seq(min_p,max_p,.2)))
p4 <- apply(p, 3, function(x) bind_cols(data.frame(x), crossing(happy_c = seq(min_h,max_h,.2), purposeful_c = seq(min_p,max_p,.2))))
p4 <- ldply(p4)

broom.mixed::tidy(m)

m_h <- mean(nested_emo_ct$data[[1]]$happy, na.rm = T)
m_p <- mean(nested_emo_ct$data[[1]]$purposeful, na.rm = T)

p4 %>%
  select(.id, Estimate, happy_c, purposeful_c) %>%
  mutate(happy = happy_c + m_h
         , purposeful = purposeful_c + m_p) %>%
  pivot_wider(names_from = ".id", values_from = "Estimate") %>%
  mutate(col = sqrt(happycdelta^2 + purposefulcdelta^2)) %>%
  ggplot(aes(x = happy, y = purposeful, u = happycdelta, v = purposefulcdelta)) + 
    geom_quiver(aes(color = col))   +
    geom_hline(aes(yintercept = m_h)) + 
    geom_vline(aes(xintercept = m_p)) + 
    scale_color_gradient(low = "gray80", high = "black") +
    labs(x = "Purpose Level", y = "Happy Level", title = "") +
    theme_classic() +
    theme(legend.position = "none",
          strip.background = element_rect(fill = "black"),
          strip.text = element_text(face = "bold", color = "white", size = rel(1.2)),
          axis.text = element_text(face = "bold", color = "black"),
          axis.title = element_text(face = "bold", size = rel(1.1)),
          plot.title = element_text(face = "bold", hjust = .5))
```

## Effect size (optional)  
<!-- If applicable, specify a predicted effect size or a minimum effect size of interest for all the effectstested in your statistical analyses. -->

Enter your response here.

## Statistical power (optional)  
<!-- Present the statistical power available to detect the predicted effect size or the smallest effect size of interest. Use the sample size after updating for missing data and outliers. -->

Enter your response here.

## Inference criteria (optional)

```{=html}
<!-- What criteria will you use to make inferences? Please describe the information youÍll use (e.g. p-values, bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this?

p-values, confidence intervals, and effect sizes are standard means for making an inference, and any level is acceptable, though some criteria must be specified in this or previous fields. Bayesian analyses should specify a Bayes factor or a credible interval. If you are selecting models, then how will you determine the relative quality of each? In regards to multiple comparisons, this is a question with few "wrong" answers. In other words, transparency is more important than any specific method of controlling the false discovery rate or false error rate. One may state an intention to report all tests conducted or one may conduct a specific correction procedure; either strategy is acceptable.

Example: We will use the standard p<.05 criteria for determining if the ANOVA and the post hoc test suggest that the results are significantly different from those expected if the null hypothesis were correct. The post-hoc Tukey-Kramer test adjusts for multiple comparisons. -->
```

Enter your response here.

## Assumption Violation/ Model Non-Convergence (optional)  
<!-- What will you do should your data violate assumptions, your model not converge, or some otheranalytic problem arises?   -->

Enter your response here.

## Reliability and Robustness testing (optional)  
<!-- Provide a series of decisions or tests about evaluating the strength, reliability, or robustness of your finding. This may include within-study replication attempts, additional covariates, cross-validation, applying weights, selectively applying constraints in an SEM context (e.g., comparingmodel fit statistics), overfitting adjustment techniques used, or some other simulation/sampling/bootstrapping method. -->

Enter your response here.

## Exploratory analyses (optional)

```{=html}
<!-- If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.

Example: We expect that certain demographic traits may be related to taste preferences. Therefore, we will look for relationships between demographic variables (age, gender, income, and marital status) and the primary outcome measures of taste preferences. -->
```
Enter your response here.

# Other

## Other (Optional)

<!-- If there is any additional information that you feel needs to be included in your preregistration, please enter it here. Literature cited, disclosures of any related work such as replications or work that uses the same data, or other context that will be helpful for future readers would be appropriate here. -->

Enter your response here.

# References

## 

```{=tex}
\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}
```
\noindent
