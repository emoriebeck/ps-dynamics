---
title           : "Personality-Situation Transactions as Coupled Systems"
shorttitle      : "My preregistration"
date            : "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"
author: 
  - name        : Emorie D Beck
    affiliation : Northwestern University Feinberg School of Medicine
  - name        : Niclas Kuper
    affiliation : Universität Bielefeld
  - name        : Kai T Horstmann
    affiliation : Humboldt-Universität zu Berlin
  - name        : Joshua J Jackson
    affiliation : Washington University in St. Louis
# affiliation:
#   - id          : 1
#     institution : 
#   - id          : 2
#     institution : Konstanz Business School
#   - id          : 3
#     institution : Konstanz Business School
#   - id          : 4
#     institution : Washington University in St. Louis
# output: prereg::cos_prereg
output:
  html_document:
    theme: united
    highlight: tango
    df_print: paged
    code_folding: show
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
  
bibliography: r-references.bib
biblio-style: "apalike"
csl: "apa-6th-edition.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```

```{r}
library(knitr)
library(brms)
library(lubridate)
library(plyr)
library(tidyverse)
library(ggquiver)
```

# Study Information

## Title

<!-- Provide the working title of your study. It may be the same title that you submit for publication of your final manuscript, but it is not a requirement. The title should be a specific and informative description of a project. Vague titles such as 'Fruit fly preregistration plan' are not appropriate.

Example: Effect of sugar on brownie tastiness. -->
`r rmarkdown::metadata$title`

## Description
<!-- Please give a brief description of your study, including some background, the purpose of the of the study, or broad research questions. The description should be no longer than the length of an abstract. It can give some context for the proposed study, but great detail is not needed here for your preregistration.

Example: Though there is strong evidence to suggest that sugar affects taste preferences, the effect has never been demonstrated in brownies. Therefore, we will measure taste preference for four different levels of sugar concentration in a standard brownie recipe to determine if the effect exists in this pastry. -->
There has long been recognition that person and situation characteristics interact in producing behavior. However, estimating such person-situation interactions or transactions has remained largely elusive. There are several reasons why this is the case. First, work on person-situation transactions often focuses on so-called fixed effects, or person-situation transactions on average across people, even when looking at within-person patterns. Such approaches fail to recognize that average effects of 0 may indicate a non-triviual number of individuals who have positive or negative effects. Second, most work on person-situation transactions assumes linear relationships between persons and situations. However, if person and situation variables are considered as systems, it makes little sense to consider their relationships as linear. Rather, they should be captured as non-linear interacting processes within a system.  

The proposed project aims to investigate non-linear dynamics between changes in personality states and situational states using multilevel coupled oscillator models [@butner_utilizing_2015; @butner_multilevel_2005; @butler_quantifying_2019].  

## Research Questions  
1. Are changes in personality states and situation characteristics associated with level of each? That is, are dynamics of personality states and situation characteristics related?  
2. Are there individual differences in these dynamics across people or do people show very similar dynamics? That is, are person situation associations best conceptualized as idiographic or nomothetic?  
3. How consistent are these across studies? Are these patterns robust to different time frames, measures and samples?  
4. Are individual differences in these dynamics associated with levels of nomothetic personality traits? That is, do people who are high on conscientiousness, for example, show different associations (e.g., stronger attractor strengths) compared to those low or are dynamics not associated with trait levels?  

## Hypotheses

1. Predicted average associations will be based on previous research examining personality state-situation characteristic contingencies [e.g., @kuper_individual_2022; @rauthmann_directionality_2016; @sherman_independent_2015]. Specifically, we expect that level in each of the following will be associated with changes of the other (i.e. be attractor states): 

```{r, echo = F, message = 'hide', warning = F}
tribble(
  ~Situation  , ~E, ~A, ~C, ~N, ~O,
  "Duty"      , "", "","+", "", "",
  "Intellect" , "", "", "", "","+",
  "Adversity" , "","-", "","+", "",
  "Mating"    ,"+", "", "", "", "",
  "pOsitivity","+", "", "","-", "",
  "Negativity","-", "", "","+", "",
  "Deception" , "","-", "","+", "",
  "Sociality" ,"+","+", "", "", ""
) %>% kable(.)
```

2. Consistent with prior work, we expect that there will be individual differences in both location and strength of attractors, as well as that people will differ in the number of attractors.  

3. Prior multi-study investigations of personality-situation transactions show similar patterns in cross-sectional and lagged associations. However, because our approach is more dynamic and the time scale of the studies varies, we expect that studies with more similar designs [e.g. @sherman_independent_2015; @horstmann_unveiling_2021] will be more similar to each other than studies with less similar designs.  

4. Based on prior work examining if...then contingencies of personality and their associations with trait measures, we expect small associations with trait measures and that these will be stronger when not accounting for variability due to situations.  

# Data Description  
## Datasets used  

<!-- Name and briefly describe the dataset(s), and if applicable, the subsets of the data you plan to use.Useful information to include here is the type of data (e.g., cross-sectional or longitudinal), the general content of the questions, and some details about the respondents. In the case of longitudinal data, information about the survey’s waves is useful as well. Mention the most relevant information so that readers do not have to search for the information themselves. -->

### Sample 1: Personality and Interpersonal Roles Study (PAIRS)  
The PAIRS study was a seven wave longitudinal study collected at Washington University in St. Louis. Approximately 350 individuals completed at least one wave of survey data, experience sampling method data, and electronically activated recorder data. In the proposed study, we will be using the third wave of ESM data, which corresponds to the seventh wave of survey data. Although all waves collected a variety of data on personality, emotions, situations, and more, the third wave additionally included a measure of situation characteristics, the DIAMONDS. In the proposed study, we will make sure of 9 indicators of Big Five personality (representing each of the Big Five except Openness) and 8 indicators of situations.  

### Sample 2: Intentional Personality Change Study (IPCS)  
The IPCS study is an ongoing longitudinal study collected at Washington University in St. Louis. Approximately 200 individuals completed the first wave of survey and ESM responses. In the proposed study, we will use the first wave of ESM data, which includes both measures of personality states as well as the DIAMONDS indicators. Specifically, we will use 15 indicators of Big Five personality (3 for each of the Big Five) and 8 indicators of situations.  

### Sample 3: Data from Sherman et al., 2015  
Sherman and colleagues (2015) collected a single wave of experience sampling responses at Florida Atlantic University. Approximately 200 individuals responded to ESM surveys 8 times per day for one week. In the proposed study, we will use the measures of personality states (7 items from HEXACO) as well as the 8 items in the S8-I DIAMONDS scale.   

### Sample 4: Data from @horstmann_unveiling_2021
Horstmann and colleages (2021) conducted a reanalysis of Sherman and colleagues' data and collected a replication and follow-up study in a German sample. Approximately 200 individuals completed ESM surveys 3 hours apart for two weeks.  In the proposed study, we will use the measures of personality states (7 items from HEXACO) as well as the 8 items in the S8-I DIAMONDS scale.  

## Data availability  
<!-- Specify the degree to which the datasets are open or publicly available. -->
Dataset   |   Availability  
-------   |   -----------
Sample 1: PAIRS   |   The dataset is publicly available  
Sample 2: IPCS    |   The dataset is publicly available  
Sample 3 [@sherman_independent_2015]         |   The dataset is available through protected access  
Sample 4 [@horstmann_unveiling_2021]         |   The dataset is available through protected access  
<!-- The dataset is publicly available   -->
<!-- The dataset is available through protected access   -->
<!-- The dataset is not publicly available   -->

## Data access (optional)
<!-- If there are any restrictions to accessing the dataset, please describe this here. -->
Although most of the data are publically available, the data maintainers request contacting them in order to avoid data overuse or overlap in their use.  

Dataset   |   Availability  
-------   |   -----------
Sample 1: PAIRS   |   Please contact Simine Vazire, simine@gmail.com  
Sample 2: IPCS    |   Please contact Emorie Beck, emorie_beck@alumni.brown.edu  
Sample 3          |   Please contact Ryne Sherman, rsherman@hoganassessments.com  
Sample 4          |   Please contact Kai Horstmann, kai.horstmann@hu-berlin.de  

## Data collection procedures  
<!-- If the data collection procedure is well documented, provide a link to that information. If the data collection procedure is not well documented, describe, to the best of your ability, how data were collected. Describe the representativeness of the sample and any possible biases stemming from the data collection. -->

### Sample 1: PAIRS  
[Adapted from @beck_consistency_2020]  

Undergraduate students at Washington University completed experience sampling method (ESM) surveys as part of the longitudinal Personality and Intimate Relationships Study (PAIRS; Vazire, Wilson, Solomon, Bollich, Harris, Weston, Mike, & Jackson, 2015). For Wave 3, 134 (76.7% female) students with a mean age of 19.0 (SD = 1.67) completed ESM surveys. For each wave, participants were paid \$20 for the laboratory portion of each assessment and entered into a lottery with the chance to win \$100 for completing ESM surveys (if all ESM surveys were completed, the odds of winning were 1 in 10). Participants’ self-reported ethnicities indicated that 56\% identified as Caucasian, 23\% as Asian, 9\% as Black, and 12\% as other. 2\% of participants did not report their ethnicities. 

Before completing the ESM component, participants first completed a two-hour laboratory experiment in which they completed multiple questionnaires as well as several other tasks, which will not be considered in the current study. After completing the laboratory portion, the researchers provided participants with instructions on the ESM component of the study. Participants received four emails per day with links to the ESM survey for two weeks. Including a practice survey, there were thus 59 possible surveys for each participant. 

Participants responded to questions about their situation, emotions, and behavior in the last hour. Nine personality items were taken from the BFI-44 (John, Naumann, & Soto, 2008), but were modified to reflect the collection periods of the ESM survey (e.g. “From 5-6 pm, how engaged were you?”). As noted in Wilson, Thompson, and Vazire (2016), “The shortened BFI scale was comprised of two items per construct taken from the original BFI-44, making sure that each item (a) made sense at the state level; (b) assessed a different facet of the respective Big Five construct; (c) avoided difficult vocabulary words, and (d) had a comparatively high item-total correlation” (p. 4). Participants responded on a 5-point scale from 1 “Not a lot” to 5 “Very.” With the exception of Agreeableness items (2), which were only collected if the participant indicated they were interacting with someone in the previous hour, participants responded to all items at each measurement point. In addition, items from the Openness to Experience domain were not included. In this third wave, an ultra brief measure of the DIAMONDS, the S8-I, was included. A few additional state manifestations of personality were also included, measuring participants' state self-esteem, positve emotion, and negative emotion, each of which were measured in the same way as the BFI items.  

### Sample 2: IPCS  
Participants in this study were drawn from a larger study personality intervention study.

Participants responded to two types of surveys: trait and state (Experience Sampling Method; ESM) measures, for which they were paid separately. For the first wave, which is the only wave used in the present study, participants were recruited from the psychology subject pool at Washington University in St. Louis. Participants were told that the study posted on the recruitment website was the first wave of a longer longitudinal study they would be offered the opportunity to take part in.

Participants were brought into the lab between October 2018 and December 2019, where a research assistant or the first author explained the study procedure to them and walked them through the consent procedure. If they consented, participants were led to a room where they could fill out a form to opt into the ESM portion of the study. They then completed baseline trait measures using the Qualtrics Survey Platform. After, the participants were debriefed, paid \$10 in cash and, if they opted into the ESM portion of the study, the ESM survey procedure was explained to them. 

Participants then received ESM measures 4 times a day for a two weeks (max n = 56). The survey platform was built by the first author using the jsPsych library. Additional javascript controllers were written for the purpose of this study and are available on the first author's GitHub. Start times were based on times participants indicated they would like to receive their first survey. Surveys were sent every 4 hours, meaning that the surveys spanned a 12 hour period from the first time participants indicated. Participants received their first survey at their chosen time on the Monday following their in-lab session. They were compensated \$0.50 for each survey completed for a maximum of $28. To incentivize responding, participants who completed at least 50 surveys received a "bonus" for a total compensation of \$30, which was distributed as an Amazon Gift Card.  

Additional information on the full sample was provided in @jackson_using_2021: 

>"The second sample consists of 199 (60 male, 154 female) students with a mean age of 19.98 (SD = 1.32). Participants were paid $10 for the laboratory portion of the study and $0.50 for each experience sampling survey completed. Participants' self-reported ethnicities indicated that 60 identified as White or European-American, 50 as Asian, 25 as Black, and 28 as other (with the remaining participants declining disclosing their race or ethnicity). The study authors have not published from this dataset. Participants completed pre-ESM question- naires in the lab and were instructed on how to complete the ESM assessments. Participants received four per day for two weeks. There were 56 possible surveys for each participant. No studies have been published using this dataset.

>Participants completed a total of 8,672 ESM surveys in Study 2. Participants who completed fewer than 20 ESM surveys were excluded, yielding final N of 161 participants (39 males, 122 females; $N_{assessments}$ = 8,261). The median number of completed surveys were 47 (range 20–56)" (Jackson, & Beck, 2021, p. 5).

Additional waves of data were completed remotely online but will not be used in the present study. See Beck \& Jackson (2021) for an overview of additional data.  

### Sample 3: Sherman et al., 2015  

From @sherman_independent_2015: 

>"Two-hundred eighteen undergraduates at Florida Atlantic University participated in this study for partial course credit.4 Eight participants only completed the first session of the study and therefore their data could not be used here. Personality data (Session 1) for one participant was lost due to a computer error; however, experience sampling data from this participant was used wherever possible. Thus, analyses reported here pertain to 210 (136 female, 73 male, 1 unknown) or 209 participants. The age range for these participants was 18 to 36 years old (M = 18.61, SD = 1.78). The ethnic breakdown for these participants was 18.2% African American, 1.4% Asian, 47.4% Caucasian, 23.0 % Hispanic/Latino, 7.6% Other, and 2.4% did not indicate or were unknown.

>"Participants arrived at the laboratory individually and were greeted by a research assistant. The research assistant explained that the goal of the study was to “understand the situations that you experience in a typical week as well as how you feel, think, and behave in these situations.” Participants were informed that the study included two parts. The first part consisted of a brief (approx. 5 min) video-recorded interview5 and a number of personality measures (see Personality Measures) using a computerized testing format. For the second part of the study, participants were sent a text message eight times per day over the course of seven consecutive days containing a personalized link to a survey about their current situation and state expressions (behavior/emotions; see Experience Sampling Measures). Because this study required text messaging capabilities and internet access on a mobile device (i.e., a smart phone), only participants who had such devices were permitted to complete the second part of the study. All participants had such capabilities, but the eight participants who did not complete the second portion of the study indicated they had technical problems.  

>"The text-messaging portion of the study began on the day immediately following the first laboratory visit. Although participants could begin the study on any weekday (M-F), the text- messaging schedule was fixed across the seven days of the week for all participants. For example, all participants received text messages at the same time of day on the Monday (Tuesday, Wednesday, etc.) that they were in the study. The text times for each day were randomly generated by choosing eight times between the hours of 9 am and 11 pm. Because we wanted to have at least 1-hr gaps between reports, a new set of times was randomly selected if any times fell within 1-hr of each other. The full text-messaging schedule is available in supplemental materials" (Sherman et al., 2015, p. 17-18).  

### Sample 4: Horstmann et al., 2021  

From Horstmann et al., 2021: 

>"The data were collected using the open-source platform formr.org (Arslan & Tata, 2015). Data collection took part in Germany. Participants were first informed about the study and required to submit their e-mail address to participate. Subsequently, participants received an e-mail with an invitation to respond to demographic questions and complete personality measures (see Trait Measures). After completing the initial assessment, participants received an e-mail every three hours with an invitation to respond to state measures (see below). The measures were presented in the same order each time. After each assessment, participants could opt out by unchecking a box. Either after opting out or after completing 50 measurement occasions, participants were directed to a website with a debriefing and a general invitation to participate in further studies. Participants then received personalized feedback via e- mail on their personality trait levels, and their trajectories in situation perception, affect, and behavior over the course of their participation. If eligible, participants could also receive course credit for their participation.

>In total, N = 1,128 participants clicked on the link to the study, 367 submitted their e-mail, and 341 participants completed the initial personality assessment. Of these, 274 provided sufficient data in the experience sampling phase of the study to be included in further analyses. Participants were on average 24.22 years old (SD = 6.35); 14.96% percent were male, 84.31% were female, and 0.73% did not indicate their gender. Most participants were enrolled in a university program (90.51%). The completion of the initial trait assessment took about 19 minutes to complete (maximum number of 80 items), and each experience sampling assessment on average about three minutes to complete. All materials required to replicate the study as well as a detailed procedure can be found on the OSF" (Horstmann et al., 2021, p. 21-22).  

## Codebook  
<!-- Some studies offer codebooks to describe their data. If such a codebook is publicly available, link, cite, or upload the document. If not, provide other available documentation. Also provide guidance on what parts of the codebook or other documentation are most relevant. -->

# Variables

<!-- In this section you can describe all variables (both manipulated and measured variables) that will later be used in your confirmatory analysis plan. In your analysis plan, you will have the opportunity to describe how each variable will be used. If you have variables which you are measuring for exploratory analyses, you are not required to list them, though you are permitted to do so. -->

## Measured variables  

```{=html}
<!-- Describe each variable that you will measure. This will include outcome measures, as well as any predictors or covariates that you will measure. You do not need to include any variables that you plan on collecting if they are not going to be included in the confirmatory analyses of this study.

Observational studies and meta-analyses will include only measured variables. As with the previous questions, the answers here must be precise. For example, 'intelligence,' 'accuracy,' 'aggression,' and 'color' are too vague. Acceptable alternatives could be 'IQ as measured by Wechsler Adult Intelligence Scale' 'percent correct,' 'number of threat displays,' and 'percent reflectance at 400 nm.'

Example: The single outcome variable will be the perceived tastiness of the single brownie each participant will eat. We will measure this by asking participants ‘How much did you enjoy eating the brownie’ (on a scale of 1-7, 1 being 'not at all', 7 being 'a great deal') and 'How good did the brownie taste' (on a scale of 1-7, 1 being 'very bad', 7 being 'very good'). -->
```

The proposed study will focus on two main categories of measures: personality states and situation characteristics. These measures differ slightly across studies, as documented below. 

## Unit of analysis (optional)
<!-- Which units of analysis (respondents, cases, etc.) will be included or excluded in your study? Taking these inclusion and exclusion criteria into account, indicate the expected sample size of the data you’ll be using for your statistical analyses. If you have a research question about a certain group you may need to exclude participants based on one or more characteristics. Be very specific when describing these characteristics so that readers will be able to redo your moves easily. -->

We will examine associations primarily at the observation level, which will provide participant-level estimates. These participant-level estimates, in turn, will be used to assess similarities and differences across studies.  

## Missing data (optional)  
<!-- What do you know about missing data in the dataset (i.e., overall missingness rate, information about differential dropout)? How will you deal with incomplete or missing data? Provide descriptive information, if available, on the amount of missing data for each variable you will usein the statistical analyses. Based on this information, provide a new expected sample size. -->

Missing data will dropped at the observation level. Because our modeling approaches using continuous time, missing responses in the ESM surveys will be accounted for by assessing change across measured intervals.  

# Knowledge of Data  
## Prior Publication/Dissemination  
<!-- List the publications, working papers, and conference presentations you have worked on that are based on the dataset you will use. For each work, list the variables you analyzed, but limit yourself to variables that are relevant to the proposed analysis. If the dataset is longitudinal, also state which wave of the dataset you analyzed. Specify the previous works for each co-author separately. -->

**Sample 1: PAIRS:**  
@beck_consistency_2020, *JPSP*; Beck, Jackson  
- Wave 1, nine indicators of the Big Five  
@jackson_using_2021, *JoP*; Beck, Jackson  
- Wave 1, nine indicators of the Big Five  

**Sample 2: IPCS:**  
@beck_idiographic_2021, *EJP*; Beck, Jackson  
- Wave 1; 15 facets of the Big Five from 25\% of the sample  
@beck_personalized_2021, *Psych Science*; Beck, Jackson  
- Wave 1: 15 facets of the Big Five and DIAMONDS indicators  
@jackson_using_2021, 2021, *JoP*; Beck, Jackson  
- Wave 1: 15 facets of the Big Five  

**Sample 3: Sherman et al., 2015:**  
Horstmann et al., 2021, *JPSP*; Horstmann  
Kuper et al., 2022 (under revision); Kuper  

**Sample 4: Horstmann et al., 2021:**  
Horstmann et al., 2021, *JPSP*; Horstmann  
Kuper et al., 2022 (under revision); Kuper  

## Prior knowledge  
<!-- Disclose any prior knowledge you may have about the dataset that is relevant for the proposed analysis. If you do not have any prior knowledge of it, please state so. Your prior knowledge could stem from working with the data first-hand, from reading previously published research, or from codebooks. Provide prior knowledge for every author separately. -->

To date, no one, to our knowledge has examined Big Five personality state-DIAMONDS situation characteristics in PAIRS or IPCS. However, the first and last author have examined (1) idiographic Big Five personality structure in PAIRS and IPCS and (2) the predictive power of personality states and DIAMONDS characteristics in predicting momentary outcomes (e.g., procrastination, loneliness). In the other studies, previous investigation have examined mean-level and individual differences in personality state-situation characteristic contingencies / associations. The second author conducted one such study using these studies but has not worked with PAIRS or IPCS previously. Although the models conducted in these studies are substantively different from those used in the present study, we will use these associations to provide strong priors on the effects.  

# Analysis Plan

<!-- You may describe one or more confirmatory analysis in this preregistration. Please remember that all analyses specified below must be reported in the final article, and any additional analyses must be noted as exploratory or hypothesis generating.

A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis. You are allowed to describe any exploratory work here, but a clear confirmatory analysis is required. -->

## Statistical models  

<!-- What statistical model will you use to test each hypothesis? Please include the type of model (e.g. ANOVA, multiple regression, SEM, etc) and the specification of the model (this includes each variable that will be included as predictors, outcomes, or covariates). Please specify any interactions, subgroup analyses, pairwise or complex contrasts, or follow-up tests from omnibus tests. If you plan on using any positive controls, negative controls, or manipulation checks you may mention that here. Remember that any test not included here must be noted as an exploratory test in your final article.

This is perhaps the most important and most complicated question within the preregistration. As with all of the other questions, the key is to provide a specific recipe for analyzing the collected data. Ask yourself: is enough detail provided to run the same analysis again with the information provided by the user? Be aware for instances where the statistical models appear specific, but actually leave openings for the precise test. See the following examples:

- If someone specifies a 2x3 ANOVA with both factors within subjects, there is still flexibility with the various types of ANOVAs that could be run. Either a repeated measures ANOVA (RMANOVA) or a multivariate ANOVA (MANOVA) could be used for that design, which are two different tests. 
- If you are going to perform a sequential analysis and check after 50, 100, and 150 samples, you must also specify the p-values you’ll test against at those three points.

Example:  We will use a one-way between subjects ANOVA to analyze our results. The manipulated, categorical independent variable is 'sugar' whereas the dependent variable is our taste index. -->

We will use two related models to test the non-linear dynamics between personality and situations. First, we will estimate a series of idiographic bivariate change as outcome models as a direct extension of @danvers_equilibria_2020. Second, we will estimate a multilevel extension. This multilevel extension both allows us to (1) estimate average within-person associations and (2) provides shrinkage on the participant-level parameters, which can improve reliability.

To demonstrate the procedure, we will use the emotion features from the IPCS study, which are not being used in the present study, to remain blinded.  

```{r, eval = T}
load("~/Library/CloudStorage/Box-Box/network/other projects/ps-oscillators/03-data/02-ipcs/01-raw-data/esm_cleaned_combined_2021-04-07.RData")
emo <- emo %>% mutate(Date = as.character(Date)
                       , Date = ifelse(SID == 212, str_replace_all(Date, "2019-01", "2020-01"), Date)
                       , Date = as.Date(Date)) %>%
  group_by(SID) %>%
  mutate(StartDate = min(Date)) %>%
  ungroup()
missing_fun <- function(d){
  first_day <- min(d$Date) # get first day
  hourBlock <- unique(d$`Hour Block 1`) # get first hour block
  max_day <- max(d$Day); max_day <- ifelse(max_day < 14, 14, max_day) # get number of days
  d2 <- d %>% #mutate(StartDate = ifelse(is.na(StartDate), min(Date, na.), StartDate))
    full_join(crossing(
      Day = seq(0,max_day,1),
      HourBlock = 1:4,
      StartDate = first_day,
      `Hour Block 1` = hourBlock)) %>% # cross existing data with "perfect" data
    arrange(Day, HourBlock) %>%
    mutate(Date = StartDate + Day,
           Hour = ifelse(is.na(Hour), `Hour Block 1` + (HourBlock-1)*4, Hour),
           Minute = ifelse(is.na(Minute), "00", Minute))
  d2$Date[d2$Hour > 23] <- d2$Date[d2$Hour > 23] + 1 # some day blocks span days
  d2$Hour[d2$Hour > 23] <- d2$Hour[d2$Hour > 23] - 24 # some day blocks span days
  d2 <- d2 %>% mutate(
    Full_Date = sprintf("%s %s:%s", as.character(Date), Hour, Minute)) %>%
    select(-`Hour Block 1`, -StartDate) 
}

# create a data frame of timing info 
ipcs_times <- emo %>% 
  select(SID, StartDate, Date, Hour, Minute, Day, `Hour Block 1`, HourBlock) %>%
  distinct() %>%
  mutate(Minute = str_remove_all(Minute, ".csv"),
         Minute = ifelse(as.numeric(Minute) < 10, sprintf("0%s", Minute), Minute)) %>%
  arrange(SID, Date) %>%
  group_by(SID) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, missing_fun)) %>%
  unnest(data) %>%
  arrange(SID, Date, Hour) %>%
  group_by(SID) %>%
  mutate(all_beeps = seq(1, n(), 1)) %>%
  ungroup()

emo <- emo %>% 
  select(SID, trait, responses2, Date, Hour, Minute, Day, HourBlock) %>%
  mutate(Minute = str_remove_all(Minute, ".csv")
         , responses2 = as.numeric(responses2)) %>%
  filter(trait %in% c("happy", "purposeful")) %>%
  full_join(ipcs_times) %>%
  distinct() %>%
  arrange(SID, all_beeps, trait)

emo_ct <- emo %>%
  filter(!is.na(trait)) %>%
  pivot_wider(names_from = "trait", values_from = "responses2") %>%
  mutate(Full_Date = ifelse(is.na(Full_Date), sprintf("%s %s:%s", as.character(Date), Hour, Minute), Full_Date)) %>%
  group_by(SID) %>%
  arrange(SID, Date, Hour, Minute) %>%
  mutate(tdif = as.numeric(difftime(ymd_hm(Full_Date), lag(ymd_hm(Full_Date)), units = "hours"))) %>%
  filter(is.na(tdif) | tdif > 1) %>%
  mutate_at(vars(happy, purposeful), lst(c = ~as.numeric(scale(., center = T, scale = F)))) %>%
  mutate_at(vars(happy_c, purposeful_c), lst(delta = ~((.) - lag(.))/tdif))
```

### Idiographic  
The idiographic proceudre mirrors @danvers_equilibria_2020. Their procedure unfolds in multiple parts. 

First, the number of equilibria for the univariate personality and situation change as outcomes models are determined separately. We will begin building model by first fitting a loess model separately for each individual who has data for at least 40 points, examining the relationship between it's level (0 to 10) and (time normalized) change (-10 to 10). Code will be similar to the simulated toy data below:  

```{r, eval = T}
nested_emo_ct <- emo_ct %>% 
  group_by(SID) %>%
  nest() %>%
  filter(map_dbl(data, nrow) > 25) %>%
  ungroup()

mh <- loess(happy_c_delta ~ happy_c, data = nested_emo_ct$data[[1]]); mh # estimate loess model 
mp <- loess(purposeful_c_delta ~ purposeful_c, data = nested_emo_ct$data[[1]]);mp # estimate loess model 
```

Based on the model, we will determine the order of the relationship based on the number of times the loess line crosses the X-axis (i.e., the sign of the relationship between level and change changes). Thus, if the line crosses once, it would be a first order (linear) relationship. If twice, a second-order quadratic relationship. We will not examine past quadratic because of power concerns.  

```{r, eval=T}
round_p1_down <- function(x){
  x <- round(x, 2)
  sp_x <- str_split(x, pattern = "[.]")[[1]]
  if(sign(x) == -1) sp_x[2] <- round_any(as.numeric(sp_x[2]), 10, ceiling)
  sp_x[2] <- str_sub(sp_x[2], 1, 1)
  y <- as.numeric(paste(sp_x[1], sp_x[2], sep = "."))
}

min_h <- round_p1_down(min(nested_emo_ct$data[[1]]$happy_c, na.rm = T)); min_p <- round_p1_down(min(nested_emo_ct$data[[1]]$purposeful_c, na.rm = T))
max_h <- round_p1_down(max(nested_emo_ct$data[[1]]$happy_c, na.rm = T)); max_p <- round_p1_down(max(nested_emo_ct$data[[1]]$purposeful_c, na.rm = T))

ph <- predict(mh, newdata = tibble(happy_c = seq(min_h, max_h, .2))) # get loess predictions
pp <- predict(mp, newdata = tibble(purposeful_c = seq(min_p, max_p, .2))) # get loess predictions

(num_equil_h <- sum(sign(ph) != sign(lag(ph)), na.rm = T))# count sign changes = number of equilibria
(num_equil_p <- sum(sign(pp) != sign(lag(pp)), na.rm = T))# count sign changes = number of equilibria
```

Then, we will combine this information and run the bivariate model. In these models, we will predict changes in personality states and situation characteristics from their level and their difference in level (i.e. their interaction). The form of the model is as follows: 


$\Delta~Personality_{it} = b_{0t,p} + b_{1t,p}*Personality_{it} + b_{2t,p}*Situation_{it} + b_{3tp}*Personality_{it,p}*Situation_{it,p} + \epsilon_{it,p}$  
$\Delta~Situation_{it} = b_{0t,s} + b_{1t,s}*Personality_{it} + b_{2t,s}*Situation_{it} + b_{3t,s}*Personality_{it}*Situation_{it} + \epsilon_{it,s}$  

, where $i$ indicates individual $i$, $t$ indicates observation $t$ for individual $i$, and $p$ and $s$ indicate main effects for different outcomes since predictors are shared. $\Delta~Personality_{it}$ is the first derivative (i.e. velocity) of the personality state indicator, $\Delta~Situation_{it}$ is the first derivative of the situation characteristic indicator, $Personality_{it}$ is the level of the personality state at time $t$, $Situation_{it}$ is the level of the situation characeristic at time $t$.  

$b_{10,p}$ is the strength of the equilibria point for the personality state, adjusting for situation characteristics and the difference (interaction) between the personality state and situation characteristics. $b_{10,s}$ is the strength of the equilibria point for the situation characteristic, adjusting for personality state and the difference (interaction) between the personality state and situation characteristics. 

In these models, including an interaction can move equilbria points or govern their presence. Thus, $b_{30,p}$ and $b_{30,s}$ capture the displacement of the equlibria points. 

To find the equilibria points, we simply solve the equations when $\Delta~Personality_{it}$ and $\Delta~Situation_{it}$ are equal to zero. In other words for personality, we solve: 
$0 = b_{00,p} + b_{10,p}*Personality_{it} + b_{20,p}*Situation_{it} + b_{30,p}*Personality_{it,p}*Situation_{it,p}$, subbing in the estimated coefficients.  

```{r, eval = T}
# generate model formula based on loess equilibria 
rhs_h <- "happy_c"; rhs_p <- "purposeful_c"
if(num_equil_h > 1) rhs_h <- c("happy_c", "happy_c_2")
if(num_equil_p > 1) rhs_h <- c("purposeful_c", "purposeful_c_2")
rhs_h <- paste0(paste(rhs_h, rhs_p, sep = " * "), collapse = " + ")
rhs_p <- paste0(paste(rhs_h, rhs_p, sep = " * "), collapse = " + ")

fh <- paste(c("happy_c_delta", rhs_h), collapse = " ~ ")
fp <- paste(c("purposeful_c_delta", rhs_p), collapse = " ~ ")
f2 <- mvbrmsformula(bf(fp), bf(fh)); f2

# m <- brm(f2, data = nested_emo_ct$data[[1]], iter = 1000, warmup = 500, cores = 4)
# save(m, file = "~/Library/CloudStorage/Box-Box/network/other projects/ps-oscillators/01-prereg/sample_idio_mod.RData")
load("~/Library/CloudStorage/Box-Box/network/other projects/ps-oscillators/01-prereg/sample_idio_mod.RData")
p <- predict(m, newdata = crossing(happy_c = seq(min_h,max_h,.2), purposeful_c = seq(min_p,max_p,.2)))
p4 <- apply(p, 3, function(x) bind_cols(data.frame(x), crossing(happy_c = seq(min_h,max_h,.2), purposeful_c = seq(min_p,max_p,.2))))
p4 <- ldply(p4)

broom.mixed::tidy(m)

m_h <- mean(nested_emo_ct$data[[1]]$happy, na.rm = T)
m_p <- mean(nested_emo_ct$data[[1]]$purposeful, na.rm = T)

p4 %>%
  select(.id, Estimate, happy_c, purposeful_c) %>%
  mutate(happy = happy_c + m_h
         , purposeful = purposeful_c + m_p) %>%
  pivot_wider(names_from = ".id", values_from = "Estimate") %>%
  mutate(col = sqrt(happycdelta^2 + purposefulcdelta^2)) %>%
  ggplot(aes(x = happy, y = purposeful, u = happycdelta, v = purposefulcdelta)) + 
    geom_quiver(aes(color = col))   +
    geom_hline(aes(yintercept = m_h)) + 
    geom_vline(aes(xintercept = m_p)) + 
    scale_color_gradient(low = "gray80", high = "black") +
    labs(x = "Purpose Level", y = "Happy Level", title = "") +
    theme_classic() +
    theme(legend.position = "none",
          strip.background = element_rect(fill = "black"),
          strip.text = element_text(face = "bold", color = "white", size = rel(1.2)),
          axis.text = element_text(face = "bold", color = "black"),
          axis.title = element_text(face = "bold", size = rel(1.1)),
          plot.title = element_text(face = "bold", hjust = .5))
```

### MLM

Multilevel models have become standard in psychology and beyond for nested data that violate assumptions of independence of errors in standard linear regression. Using maximum likelihood estimation, such models pull apart variance at different levels -- in our case observations and persons -- that allow us to understand associations without violating assumptions. In our case, this means that we can look at average associations between personality states and situations across people as well as person-specific associations. However, these average associations are not the same as simply averaging the idiographic estimates already discussed. Rather, a hallmark of multilevel models is shrinkage, in which more extreme observations are shrunk toward the mean. Doing so can improve the reliability of the estimates, assuming that extreme examples actually reflect more error. A pure idiographic framework requires no reference to other people, so we choose to test an MLM approach in addition to an idiographic approach to understand the degree of shrinkage that emerges from these estimates and to get an estimate of the average association across people.  

To estimate coupled non-linear oscillations between personality states and situation characteristics, we will use a series of multivariate multilevel change as outcome models. In these models, we will predict changes in personality states and situation characteristics from their level and their difference in level (i.e. their interaction). The form of the model is as follows: 

Level 1:  
$\Delta~Personality_{it} = \beta_{0t,p} + \beta_{1t,p}*Personality_{it} + \beta_{2t,p}*Situation_{it} + \beta_{3tp}*Personality_{it,p}*Situation_{it,p} + \epsilon_{it,p}$  
$\Delta~Situation_{it} = \beta_{0t,s} + \beta_{1t,s}*Personality_{it} + \beta_{2t,s}*Situation_{it} + \beta_{3t,s}*Personality_{it}*Situation_{it} + \epsilon_{it,s}$  

Level 2:  
$\beta_{0t,p} = \gamma_{00,p} + u_{0t,p}$  
$\beta_{1t,p} = \gamma_{10,p} + u_{1t,p}$  
$\beta_{2t,p} = \gamma_{20,p} + u_{2t,p}$  
$\beta_{3t,p} = \gamma_{30,p} + u_{3t,p}$  

$\beta_{0t,s} = \gamma_{00,s} + u_{0t,s}$  
$\beta_{1t,s} = \gamma_{10,s} + u_{1t,s}$  
$\beta_{2t,s} = \gamma_{20,s} + u_{2t,s}$  
$\beta_{3t,s} = \gamma_{30,s} + u_{3t,s}$, 

where $\Delta~Personality_{it}$ is the first derivative (i.e. velocity) of the personality state indicator, $\Delta~Situation_{it}$ is the first derivative of the situation characteristic indicator, $Personality_{it}$ is the level of the personality state at time $t$, $Situation_{it}$ is the level of the situation characeristic at time $t$.  

$\gamma_{10,p}$ is the strength of the equilibria point for the personality state, adjusting for situation characteristics and the difference (interaction) between the personality state and situation characteristics. $\gamma_{10,s}$ is the strength of the equilibria point for the situation characteristic, adjusting for personality state and the difference (interaction) between the personality state and situation characteristics. 

In these models, including an interaction can move equilbria points or govern their presence. Thus, $\gamma_{30,p}$ and $\gamma_{30,s}$ capture the displacement of the equlibria points. 

To find the equilibria points, we simply solve the equations when $\Delta~Personality_{it}$ and $\Delta~Situation_{it}$ are equal to zero. In other words for personality, we solve: 
$0 = \gamma_{00,p} + \gamma_{10,p}*Personality_{it} + \gamma_{20,p}*Situation_{it} + \gamma_{30,p}*Personality_{it,p}*Situation_{it,p}$, subbing in the estimated coefficients. 

The basic code is below. However, there is no demonstrative case run here because it would take hours. The procedure 

```{r, eval = F}

fp <- paste(c("happy_delta", "happy_c*purposeful_c + (happy_c*purposeful_c | SID)"), collapse = " ~ ")
fs <- paste(c("purposeful_delta", "happy_c*purposeful_c + (happy*purposeful_c | SID)"), collapse = " ~ ")
f2 <- mvbrmsformula(bf(fp), bf(fs))

m <- brm(f2, data = emo_ct, iter = 1000, warmup = 500, cores = 4)

fx <- fixef(m) 

rf <- coef(m, probs = c(0.025, 0.975))[[1]] %>% array_tree(3) %>% 
      tibble(term = names(.), data = .) %>% 
      mutate(data = map(data, ~(.) %>% data.frame %>% 
        rownames_to_column("SID"))) %>% 
      unnest(data) %>% 
      select(term, SID, estimate = Estimate, conf.low = Q2.5, conf.high = Q97.5)
```


<!-- ## Effect size (optional)   -->
<!-- If applicable, specify a predicted effect size or a minimum effect size of interest for all the effectstested in your statistical analyses. -->

<!-- Enter your response here. -->

## Statistical power (optional)  
<!-- Present the statistical power available to detect the predicted effect size or the smallest effect size of interest. Use the sample size after updating for missing data and outliers. -->

Power guidelines for non-linear dynamic systems models like the coupled oscillator are not well established and depend on a variety of factors. However, estimates range from 50-100 observations. We will perform a number of sensitivity analyses examining the robustness of these relationships, such using strongly regularizing priors and correlating effect sizes with sample sizes.

## Inference criteria (optional)

<!-- What criteria will you use to make inferences? Please describe the information youÍll use (e.g. p-values, bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this?

p-values, confidence intervals, and effect sizes are standard means for making an inference, and any level is acceptable, though some criteria must be specified in this or previous fields. Bayesian analyses should specify a Bayes factor or a credible interval. If you are selecting models, then how will you determine the relative quality of each? In regards to multiple comparisons, this is a question with few "wrong" answers. In other words, transparency is more important than any specific method of controlling the false discovery rate or false error rate. One may state an intention to report all tests conducted or one may conduct a specific correction procedure; either strategy is acceptable.

Example: We will use the standard p<.05 criteria for determining if the ANOVA and the post hoc test suggest that the results are significantly different from those expected if the null hypothesis were correct. The post-hoc Tukey-Kramer test adjusts for multiple comparisons. -->

Inference criteria will be based on the 95\% Credible interval of the model terms at the participant or study level.

In this study, we will not adjust for multiple testing. Multiple testing is a tricky issue for (at least) two reasons: First, it is only exists because of null hypothesis significance testing. If one focuses on an estimation of the effect, then multiple testing is not an issue because multiple testing only concerns rejecting nulls when unduly justified. If a null is not of concern but the precision of the estimate is more explicitly a concern, then broader CIs can be created. 

Second, within a Bayesian modeling framework (as well as certain frequentists perspectives that are more of the estimation bent compared to the hypothesis testing bent) adjustment for tests do not make any sense insomuch as the posterior distribution is the logical consequence of the likelihood and the priors. Adjusting the posterior distribution in any way is thus manipulating your model results based on factors that were not modeled. As a result, the model is not generative, a feature that is seen as major benefit. At a simpler level, p-values are not a part of Bayesian framework as there is no null hypothesis distribution. 

Gelman, A., Hill, J., & Yajima, M. (2012). Why we (usually) don't have to worry about multiple comparisons. Journal of Research on Educational Effectiveness, 5(2), 189-211.

## Assumption Violation/ Model Non-Convergence (optional)  
<!-- What will you do should your data violate assumptions, your model not converge, or some otheranalytic problem arises?   -->

If our models fail to converge, we will increase the number of warm-up samples and total samples by 1.5x, increase adapt_delta to .99, and increase the number of trees to 20. 

## Reliability and Robustness testing (optional)  
<!-- Provide a series of decisions or tests about evaluating the strength, reliability, or robustness of your finding. This may include within-study replication attempts, additional covariates, cross-validation, applying weights, selectively applying constraints in an SEM context (e.g., comparingmodel fit statistics), overfitting adjustment techniques used, or some other simulation/sampling/bootstrapping method. -->

We are using four samples in order to better understand the robustness of our findings, and coupling idiographic and multilevle approaches to better estimate the reliability of our models.  

## Exploratory analyses (optional)

```{=html}
<!-- If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.

Example: We expect that certain demographic traits may be related to taste preferences. Therefore, we will look for relationships between demographic variables (age, gender, income, and marital status) and the primary outcome measures of taste preferences. -->
```
We will also test whether equilibria location and strength are associated with interindividual differences in levels of personality characteristics measured via nomothetic inventories. These are documented in the codebook in this preregistration.  

# Other

<!-- ## Other (Optional) -->

<!-- If there is any additional information that you feel needs to be included in your preregistration, please enter it here. Literature cited, disclosures of any related work such as replications or work that uses the same data, or other context that will be helpful for future readers would be appropriate here. -->

<!-- Enter your response here. -->

# References

## 

```{=tex}
\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}
```
\noindent
